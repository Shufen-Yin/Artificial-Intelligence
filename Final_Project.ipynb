{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shufen-Yin/Artificial-Intelligence/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Load dataset\n",
        "# 1️⃣ Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import io\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "P_MmFUdEh2nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️⃣ Upload the dataset from local machine\n",
        "uploaded = files.upload()  # This will prompt you to choose the file\n",
        "\n",
        "# 3️⃣ Load the uploaded CSV\n",
        "file_name = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n"
      ],
      "metadata": {
        "id": "3mBMMYY2jDKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3️⃣ Define column names (from UCI documentation)\n",
        "columns = ['Sex','Length','Diameter','Height','Whole_weight','Shucked_weight','Viscera_weight','Shell_weight','Rings']\n",
        "\n",
        "# 4️⃣ Load the dataset\n",
        "df = pd.read_csv(io.BytesIO(uploaded[file_name]), header=None, names=columns)\n"
      ],
      "metadata": {
        "id": "K2LYMTJ-kMRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2 Data Preprocessing and Exploration\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 1 Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "9sCy_TlCfLQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 Encode categorical variable 'Sex' using one-hot encoding\n",
        "df_encoded = pd.get_dummies(df, columns=['Sex'], drop_first=True)  # drop_first=True to avoid dummy variable trap\n",
        "\n",
        "# 3 Visualize numeric feature distributions\n",
        "numeric_features = df_encoded.drop('Rings', axis=1)\n",
        "numeric_features.hist(bins=20, figsize=(12,10))\n",
        "plt.suptitle(\"Numeric Feature Distributions\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6tQsrQ-aka-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 Boxplots for outlier detection\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(data=numeric_features)\n",
        "plt.title(\"Boxplot for Numeric Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F-76V3NnkgUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 Correlation heatmap\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(df_encoded.corr(), cmap='coolwarm', annot=False)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Cj_J55J_lJek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(numeric_features)\n",
        "df_scaled = pd.DataFrame(X_scaled, columns=numeric_features.columns)\n",
        "df_scaled['Rings'] = df_encoded['Rings']"
      ],
      "metadata": {
        "id": "ss1oTcy_lNtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: check Rings distribution (target)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(df['Rings'], bins=20, kde=True)\n",
        "plt.title(\"Distribution of Rings (Target)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8OKsYl0rlRy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 Split data into train/test sets\n",
        "X = df_scaled.drop('Rings', axis=1)\n",
        "y = df_scaled['Rings']  # Regression task\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "kyW8mgfUleUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3 Model Selection and Development\n",
        "# Regression Example: Predicting Rings\n",
        "# 1️⃣ Import regression models and metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 2️⃣ Initialize model\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# 3️⃣ Train model\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# 4️⃣ Predict on test set\n",
        "y_pred = rf_reg.predict(X_test)\n",
        "\n",
        "# 5️⃣ Evaluate performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R^2 Score: {r2:.2f}\")\n",
        "\n",
        "# 6️⃣ Optional: Cross-validation\n",
        "cv_scores = cross_val_score(rf_reg, X_train, y_train, cv=5, scoring='r2')\n",
        "print(f\"Cross-validation R^2 scores: {cv_scores}\")\n",
        "print(f\"Average CV R^2 score: {np.mean(cv_scores):.2f}\")\n",
        "\n",
        "# 7️⃣ Hyperparameter tuning (GridSearch)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_reg, param_grid=param_grid,\n",
        "                           cv=3, scoring='r2', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "id": "4K24dMqpmMfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the regression task, I used a Random Forest Regressor to predict the number of Rings (which approximates the age of the abalone).\n",
        "After hyperparameter tuning with GridSearchCV, the best model achieved a test MSE of 5.10 and an R² score of 0.53, with an average cross-validation R² of 0.54.\n",
        "This indicates that the model can explain around 53–54% of the variance in the target variable. The cross-validation scores are close to the test score, suggesting that the model is relatively stable and not heavily overfitting."
      ],
      "metadata": {
        "id": "AHz4ShGysNuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Example: Converting Rings into Categories\n",
        "# Convert Rings into 3 categories: young, adult, old\n",
        "bins = [0, 8, 12, np.max(y)]\n",
        "labels = ['Young', 'Adult', 'Old']\n",
        "y_class = pd.cut(y, bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "# Split again for classification\n",
        "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
        "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
        ")\n",
        "\n",
        "# Import classification models and metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize model\n",
        "rf_cls = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train model\n",
        "rf_cls.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "# Predict\n",
        "y_pred_cls = rf_cls.predict(X_test_cls)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test_cls, y_pred_cls)\n",
        "print(f\"Classification Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_cls, y_pred_cls))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_cls, y_pred_cls))\n",
        "\n",
        "# Optional: Cross-validation\n",
        "cv_scores_cls = cross_val_score(rf_cls, X_train_cls, y_train_cls, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy scores: {cv_scores_cls}\")\n",
        "print(f\"Average CV accuracy: {np.mean(cv_scores_cls):.2f}\")\n"
      ],
      "metadata": {
        "id": "OPK_7cHAmMky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the classification task, I transformed the continuous Rings value into three age categories: Young, Adult, and Old. I trained a Random Forest Classifier and achieved an overall accuracy of 72% on the test set, with an average cross-validation accuracy of 71%, indicating consistent performance.\n",
        "\n",
        "The model performs best on the Young and Adult classes, with F1-scores of 0.76 and 0.75, respectively. Performance on the Old class is weaker (F1-score = 0.53), which can be seen in the confusion matrix where many Old samples are misclassified as Adult. This may be due to fewer samples in the Old class and overlapping feature distributions."
      ],
      "metadata": {
        "id": "KbkjZWMQsWXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4 Model Evaluation and Optimization\n",
        "#  1. Final evaluation of the classification model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Basic test set metrics\n",
        "accuracy = accuracy_score(y_test_cls, y_pred_cls)\n",
        "precision = precision_score(y_test_cls, y_pred_cls, average='weighted')\n",
        "recall = recall_score(y_test_cls, y_pred_cls, average='weighted')\n",
        "f1 = f1_score(y_test_cls, y_pred_cls, average='weighted')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Weighted Precision: {precision:.2f}\")\n",
        "print(f\"Weighted Recall: {recall:.2f}\")\n",
        "print(f\"Weighted F1-score: {f1:.2f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_cls, y_pred_cls))\n"
      ],
      "metadata": {
        "id": "fxF6CbLxnXqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Confusion matrix visualization\n",
        "cm = confusion_matrix(y_test_cls, y_pred_cls)\n",
        "cm_df = pd.DataFrame(cm, index=y_test_cls.unique(), columns=y_test_cls.unique())\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm_df, annot=True, fmt=\"d\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Cross-validation for robustness\n",
        "cv_scores_cls = cross_val_score(rf_cls, X_train_cls, y_train_cls, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation accuracy scores: {cv_scores_cls}\")\n",
        "print(f\"Average CV accuracy: {np.mean(cv_scores_cls):.2f}\")"
      ],
      "metadata": {
        "id": "ncGqEWufnu6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Hyperparameter tuning (Grid Search) for classification\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Base model\n",
        "rf_cls = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid_cls = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid_search_cls = GridSearchCV(\n",
        "    estimator=rf_cls,\n",
        "    param_grid=param_grid_cls,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search_cls.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "print(\"Best parameters (classification):\", grid_search_cls.best_params_)\n",
        "print(\"Best CV accuracy:\", grid_search_cls.best_score_)\n",
        "\n",
        "# Use the best model\n",
        "best_rf_cls = grid_search_cls.best_estimator_\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_best = best_rf_cls.predict(X_test_cls)\n",
        "\n",
        "best_accuracy = accuracy_score(y_test_cls, y_pred_best)\n",
        "print(f\"Test accuracy with best model: {best_accuracy:.2f}\")\n",
        "print(\"\\nClassification Report (best model):\")\n",
        "print(classification_report(y_test_cls, y_pred_best))\n"
      ],
      "metadata": {
        "id": "NAPDrpRLn-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV to tune hyperparameters of the Random Forest classifier, including the number of trees, maximum depth, minimum samples to split, and feature selection strategy. The tuned model slightly improved the validation accuracy and maintained a similar performance on the test set, confirming that the model is reasonably well-optimized."
      ],
      "metadata": {
        "id": "AkVeAZfSs102"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Feature importance (simple “feature selection” discussion)\n",
        "importances = best_rf_cls.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "feat_imp.head(10).plot(kind='bar')\n",
        "plt.title(\"Top 10 Feature Importances (Classification Model)\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 important features:\")\n",
        "print(feat_imp.head(10))\n"
      ],
      "metadata": {
        "id": "0R-U036JoWh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature importance analysis shows that physical measurements such as Length, Diameter, Whole_weight, and Shell_weight are the most influential predictors of abalone age category. This is consistent with domain intuition: larger and heavier abalones tend to be older."
      ],
      "metadata": {
        "id": "UJDm9lQltdb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Regression model evaluation (short, to cover RMSE etc.)\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "y_pred_reg = rf_reg.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred_reg)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred_reg)\n",
        "\n",
        "print(f\"Test MSE: {mse:.2f}\")\n",
        "print(f\"Test RMSE: {rmse:.2f}\")\n",
        "print(f\"Test R^2: {r2:.2f}\")\n",
        "\n",
        "cv_scores_reg = cross_val_score(rf_reg, X_train, y_train, cv=5, scoring='r2')\n",
        "print(f\"CV R^2 scores: {cv_scores_reg}\")\n",
        "print(f\"Average CV R^2: {np.mean(cv_scores_reg):.2f}\")\n"
      ],
      "metadata": {
        "id": "cg3gDFeGoo6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the regression task, I evaluated the model using MSE, RMSE, and R². The final model achieved an RMSE of about √5.10 ≈ 2.26 and an R² of around 0.53, with cross-validation R² around 0.54. This indicates that the model explains a moderate portion of the variance but the problem is not perfectly predictable from the available features."
      ],
      "metadata": {
        "id": "i2RWd8pUtiZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. About “regularization” and “dropout”\n",
        "\n",
        "Although I did not use explicit L1/L2 regularization or dropout (which are more common in linear models and neural networks), the Random Forest model includes several hyperparameters that act as regularization mechanisms. For example, limiting max_depth and increasing min_samples_split and min_samples_leaf effectively control model complexity and reduce overfitting."
      ],
      "metadata": {
        "id": "faBd6CYZo7RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5 Model Deployment and Presentation\n",
        "# 1. Simple interactive UI in Colab (text inputs)\n",
        "# Deployment: Interactive prediction in Colab\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ipywidgets import interact, FloatSlider, Dropdown\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Make sure reuse the same scaler and columns used in training:\n",
        "# - scaler: fitted StandardScaler from Task 2\n",
        "# - feature columns: same as X.columns (after encoding)\n",
        "\n",
        "feature_names = list(X.columns)  # X is your final feature matrix\n",
        "\n",
        "print(\"Feature names used by the model:\")\n",
        "print(feature_names)\n"
      ],
      "metadata": {
        "id": "UpwAqSxaoHeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: interactive prediction function\n",
        "\n",
        "def predict_abalone_age_category(\n",
        "    Sex='M',\n",
        "    Length=0.5,\n",
        "    Diameter=0.4,\n",
        "    Height=0.15,\n",
        "    Whole_weight=0.8,\n",
        "    Shucked_weight=0.4,\n",
        "    Viscera_weight=0.2,\n",
        "    Shell_weight=0.3\n",
        "):\n",
        "    # 1. Build a single-row raw input DataFrame (before encoding)\n",
        "    input_dict = {\n",
        "        'Sex': [Sex],\n",
        "        'Length': [Length],\n",
        "        'Diameter': [Diameter],\n",
        "        'Height': [Height],\n",
        "        'Whole_weight': [Whole_weight],\n",
        "        'Shucked_weight': [Shucked_weight],\n",
        "        'Viscera_weight': [Viscera_weight],\n",
        "        'Shell_weight': [Shell_weight]\n",
        "    }\n",
        "    df_input = pd.DataFrame(input_dict)\n",
        "\n",
        "    # 2. Apply the same one-hot encoding as before\n",
        "    # In Task 2 you did: pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
        "    df_input_enc = pd.get_dummies(df_input, columns=['Sex'], drop_first=True)\n",
        "\n",
        "    # Ensure all columns match the training columns (missing ones = 0)\n",
        "    for col in feature_names:\n",
        "        if col not in df_input_enc.columns:\n",
        "            df_input_enc[col] = 0\n",
        "\n",
        "    # Reorder columns to match model input\n",
        "    df_input_enc = df_input_enc[feature_names]\n",
        "\n",
        "    # 3. Scale numeric features using the same scaler\n",
        "    X_input_scaled = scaler.transform(df_input_enc)\n",
        "\n",
        "    # 4. Predict using the trained classification model\n",
        "    # Replace best_rf_cls with your final model name if different\n",
        "    y_pred = best_rf_cls.predict(X_input_scaled)\n",
        "    y_proba = best_rf_cls.predict_proba(X_input_scaled)[0]\n",
        "\n",
        "    # 5. Show result\n",
        "    print(\"Predicted age category:\", y_pred[0])\n",
        "    print(\"Class probabilities:\")\n",
        "    for cls, p in zip(best_rf_cls.classes_, y_proba):\n",
        "        print(f\"  {cls}: {p:.2f}\")\n"
      ],
      "metadata": {
        "id": "dYn960dVp8lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a nice interactive widget:\n",
        "# Interactive UI\n",
        "interact(\n",
        "    predict_abalone_age_category,\n",
        "    Sex=Dropdown(options=['M', 'F', 'I'], value='M', description='Sex'),\n",
        "    Length=FloatSlider(min=0.1, max=0.8, step=0.01, value=0.5, description='Length'),\n",
        "    Diameter=FloatSlider(min=0.1, max=0.7, step=0.01, value=0.4, description='Diameter'),\n",
        "    Height=FloatSlider(min=0.01, max=0.3, step=0.01, value=0.15, description='Height'),\n",
        "    Whole_weight=FloatSlider(min=0.05, max=2.5, step=0.05, value=0.8, description='Whole W'),\n",
        "    Shucked_weight=FloatSlider(min=0.02, max=1.5, step=0.02, value=0.4, description='Shucked W'),\n",
        "    Viscera_weight=FloatSlider(min=0.01, max=0.8, step=0.01, value=0.2, description='Viscera W'),\n",
        "    Shell_weight=FloatSlider(min=0.02, max=1.5, step=0.02, value=0.3, description='Shell W')\n",
        ");\n"
      ],
      "metadata": {
        "id": "1s10R0W-qWGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 Model Deployment in Google Colab\n",
        "\n",
        "To demonstrate how the model can be used in practice, I deployed the final Random Forest classification model in a Google Colab notebook. I created an interactive interface using ipywidgets, where users can input the physical measurements of an abalone (sex, length, diameter, height, and different weight measurements) through sliders and a dropdown menu.\n",
        "\n",
        "When the user adjusts the inputs, the system automatically:\n",
        "\n",
        "Encodes the categorical Sex feature using the same one-hot encoding as in training.\n",
        "\n",
        "Scales the numeric features using the previously fitted StandardScaler.\n",
        "\n",
        "Feeds the processed input into the trained Random Forest classifier.\n",
        "\n",
        "Displays the predicted age category (Young, Adult, or Old) and the corresponding class probabilities.\n",
        "\n",
        "This deployment shows that the model is not only trained and evaluated offline, but can also be used interactively for decision support in a simple and user-friendly way."
      ],
      "metadata": {
        "id": "wjyseHPjqwMC"
      }
    }
  ]
}